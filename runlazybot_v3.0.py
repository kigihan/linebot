# -*- coding: utf-8 -*-

#  Licensed under the Apache License, Version 2.0 (the "License"); you may
#  not use this file except in compliance with the License. You may obtain
#  a copy of the License at
#
#       https://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#  License for the specific language governing permissions and limitations
#  under the License.

from __future__ import unicode_literals

import os
import sys
import botsetting
import requests
import re
import json
from argparse import ArgumentParser

from flask import Flask, request, abort
from linebot import (
    LineBotApi, WebhookParser
)
from linebot.exceptions import (
    InvalidSignatureError
)
from linebot.models import *

from bs4 import BeautifulSoup

app = Flask(__name__)

# get channel_secret and channel_access_token from your environment variable
channel_secret = botsetting.LINE_CHANNEL_SECRET
channel_access_token = botsetting.LINE_CHANNEL_ACCESS_TOKEN
if channel_secret is None:
    print('Specify LINE_CHANNEL_SECRET as environment variable.')
    sys.exit(1)
if channel_access_token is None:
    print('Specify LINE_CHANNEL_ACCESS_TOKEN as environment variable.')
    sys.exit(1)

line_bot_api = LineBotApi(channel_access_token)
parser = WebhookParser(channel_secret)
filter_softjob = ["[æƒ…å ±]", "[å…¬å‘Š]"]
filter_default = [
    ["default", "[å…¬å‘Š]", "[ç™¼éŒ¢]"]
]
filter_test = [
    ["soft_job", "[æƒ…å ±]"],
    ["lol"],
    ["nba", "[live]"],
    ["beauty"],
    ["baseball"]
]
filter_formal = []
i = 0
for filter_clns in filter_test:
    # print(filter_clns)    
    # #if filter_clns[0] not in ["default"]:
    # filter_clns.extend(filter_default[0][1:])
    # print("....filter 1....")
    # print(filter_clns)
    # filter_formal.extend(filter_clns)
    # print(".......filter 2 ........")
    # print(filter_formal)
    filter_test[i].extend(filter_default[0][1:])
    i += 1
print("...........FULL FILTER............")
print(filter_test)
@app.route("/callback", methods=['POST'])

def callback():
    signature = request.headers['X-Line-Signature']

    # get request body as text
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)

    # parse webhook body
    try:
        events = parser.parse(body, signature)
    except InvalidSignatureError:
        abort(400)

#     if event is MessageEvent and message is TextMessage, then echo text
#    for event in events:
#        if not isinstance(event, MessageEvent):
#            continue
#        if not isinstance(event.message, TextMessage):
#            continue
#
#        line_bot_api.reply_message(
#            event.reply_token,
#            TextSendMessage(text="U just said: " + event.message.text)
#        )

    all_template_message = TemplateSendMessage()
    carousel_template_message = TemplateSendMessage()
    simple_board_name = ""
    simple_push_rate = 90
    filter_simple = []
    for event in events:
        if isinstance(event, MessageEvent):
            # if event.message.text.lower() == 'lazybot' or event.message.text.lower() == "lazynoob":
            if event.message.text.lower() in ["lazybot", "lazbot", "lzbot", "lazynoob", "lazyn00b"]:
                all_template_message = TemplateSendMessage(
                    alt_text = 'å®‰å®‰ \n\næŒ‡ä»¤èªªæ˜è«‹è¼¸å…¥\"LzHelp\"(å¤§å°å¯«çš†å¯)',
                    template = ButtonsTemplate(
                        thumbnail_image_url = "https://farm1.staticflickr.com/369/30705578944_b898fa0458_h.jpg",
                        title = 'å®‰å®‰',
                        text = 'è«‹é¸æ“‡ä¸‹åˆ—æœå‹™',
                        actions = [
                            MessageTemplateAction(
                                label = 'PTTè¡¨ç‰¹ç‰ˆäº”å¤§ç†±é–€æ–‡ç« ',
                                text = 'BEAU'
                            ),
                            MessageTemplateAction(
                                label = 'å…¶ä»–æŒ‡ä»¤èªªæ˜',
                                text = 'LzHelp'
                            ),
                            URITemplateAction(
                                label = "å€Ÿä½ çœ‹å†°å³¶ç›¸ç°¿å–”(flickr)",
                                uri = "https://www.flickr.com/photos/132023410@N06/albums/72157673424430564"
                            )
                        ]
                    )
                )
                line_bot_api.reply_message(
                event.reply_token,
                all_template_message
                )

            if event.message.text.lower() in ["lzhelp", "lazhelp", "lazyhelp"]:
                line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text= \
                    "æŒ‡ä»¤èªªæ˜\n" + \
                    "(ğŸ˜ƒ æ‰€æœ‰æŒ‡ä»¤å¤§å°å¯«çš†å¯)\n\n" + \
                    "â¤[+]Beautyç‰ˆç†±æ–‡\n" + \
                    "(æ‰‹æ©Ÿè§€çœ‹å¯å¾—è¼ƒä½³æ•ˆæœ)\n" + \
                    "â‡Beau\n\n" + \
                    "â¤[+]æŸ¥çœ‹PTTå„ç‰ˆç†±é–€æ–‡ç« \n" + \
                    "(æ¨æ–‡æ•¸å¯ä¸è¼¸å…¥ï¼Œé è¨­50)\n" + \
                    "â‡LzPtt (ç©ºæ ¼) ç‰ˆå (ç©ºæ ¼) æ¨æ–‡æ•¸æ¨™æº–\n" + \
                    "ä»¥ä¸‹ç‚ºç¯„ä¾‹: \n" + \
                    "â‡LzPtt car\n" + \
                    "â‡LzPtt nba 80\n" + \
                    "â‡LzPtt gossiping 10\n\n" + \
                    "â¤[+]åˆ©ç”¨é—œéµå­—æœå°‹PTTçœ‹æ¿æ–‡ç« \n" + \
                    "(æ¨æ–‡æ•¸å¯ä¸è¼¸å…¥ï¼Œé è¨­50)\n" + \
                    "â‡LzPttS (ç©ºæ ¼) ç‰ˆå (ç©ºæ ¼) æœå°‹é—œéµå­— (ç©ºæ ¼) æ¨æ–‡æ•¸æ¨™æº–\n" + \
                    "ä»¥ä¸‹ç‚ºç¯„ä¾‹: \n" + \
                    "â‡LzPttS car å¿ƒå¾—\n" + \
                    "â‡LzPttS nba live 30\n" + \
                    "â‡LzPttS movie å¥½é›· 10\n")
                )

            # if event.message.text.lower() == 'è¡¨ç‰¹':
            #     all_template_message = PttBeauty()
            #     line_bot_api.reply_message(
            #     event.reply_token,
            #     TextSendMessage(text=all_template_message)
            #     )

            # if event.message.text.lower() == 'nba':
            #     all_template_message = PttNBA()
            #     line_bot_api.reply_message(
            #     event.reply_token,
            #     TextSendMessage(text=all_template_message)
            #     )

            # if event.message.text.lower() == 'nbafilm':
            #     all_template_message = PttNBAFilm()
            #     line_bot_api.reply_message(
            #     event.reply_token,
            #     TextSendMessage(text=all_template_message)
            #     )

            # if event.message.text.lower() == 'softjob':
            #     simple_board_name = "Soft_Job"
            #     simple_push_rate = 20
            #     filter_simple = filter_softjob
            #     all_template_message = ptt_simple_board(simple_board_name, simple_push_rate, filter_simple)
            #     line_bot_api.reply_message(
            #     event.reply_token,
            #     TextSendMessage(text=all_template_message)
            #     )

            if event.message.text.lower().startswith("lzptt "):
                #print(event.message.text)
                simple_board_name_input = re.split("\s*", event.message.text)
                #print(simple_board_name_input)
                simple_board_name = simple_board_name_input[1]
                #print("..............<<" + simple_board_name)
                #åƒè¼¸å…¥çš„æ¨æ–‡æ•¸
                try:
                    simple_push_rate = int(simple_board_name_input[2])
                except:
                    #print("........input push rate fail1")
                    simple_push_rate = 50
                print("........push_rate_1" + str(simple_push_rate))
                for filter_ctr in filter_test:
                    if simple_board_name == filter_ctr[0]:
                        filter_simple = filter_ctr[1:]
                if not filter_simple:
                    filter_simple = filter_default[0][1:]
                    #print(filter_simple)
                #è¨­å®šfilterï¼Œ1 = æ¨™é¡Œé»‘åå–®filter(å…§å»º)ï¼Œ2 = æ¨™é¡Œç™½åå–®filter(userè¼¸å…¥)
                simple_filter_type = 1
                all_template_message = ptt_simple_board(simple_board_name, simple_push_rate, filter_simple, simple_filter_type)
                #print(all_template_message)
                print(len(all_template_message))
                if not all_template_message:
                    all_template_message = \
                    "è«‹é™ä½æ¨æ–‡æ•¸æ¨™æº–ï¼Œè¨­å®šæ–¹å¼å¯åƒè€ƒLzPttæŒ‡ä»¤èªªæ˜: \n\n" + \
                    "LzPtt (ç©ºæ ¼) PTTç‰ˆå (ç©ºæ ¼) æ¨æ–‡æ•¸æ¨™æº–\n\n" + \
                    "ä¾‹: LzPtt NBA 70\n\n" + \
                    "æˆ–ä½¿ç”¨æŒ‡ä»¤\"LzHelp\"äº†è§£è©³ç´°è³‡è¨Š\n"
                if len(all_template_message) >= 2000:
                    all_template_message = \
                    "æ–‡ç« éå¤šï¼Œè«‹æé«˜æ¨æ–‡æ•¸ã€‚\n\n" + \
                    "LzPtt (ç©ºæ ¼) PTTç‰ˆå (ç©ºæ ¼) æ¨æ–‡æ•¸æ¨™æº–\n" + \
                    "ä¾‹: lzPtt NBA 70\n\n" + \
                    "æˆ–ä½¿ç”¨æŒ‡ä»¤\"LzHelp\"äº†è§£è©³ç´°è³‡è¨Š\n"
                line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text=all_template_message)
                )

            if event.message.text.lower().startswith("lzptts "):
                print(event.message.text)
                simple_board_name_input = re.split("\s*", event.message.text)
                #print(simple_board_name_input)
                simple_board_name = simple_board_name_input[1]
                #print("..............<<" + simple_board_name)
                try:
                    filter_simple = simple_board_name_input[2]
                    bypass_proc = 0
                except:
                    all_template_message = \
                    "è«‹è¼¸å…¥é—œéµå­—ä»¥ä¾›æœå°‹ï¼Œè¨­å®šæ–¹å¼å¯åƒè€ƒLzPttSæŒ‡ä»¤èªªæ˜: \n\n" + \
                    "LzPttS (ç©ºæ ¼) PTTç‰ˆå (ç©ºæ ¼) æœå°‹é—œéµå­— (ç©ºæ ¼) æ¨æ–‡æ•¸æ¨™æº–\n\n" + \
                    "ä¾‹: LzPttS car å¿ƒå¾—\n" + \
                    "ä¾‹: LzPttS NBA box 70\n" + \
                    "æˆ–ä½¿ç”¨æŒ‡ä»¤\"LzHelp\"äº†è§£è©³ç´°è³‡è¨Š\n"
                    bypass_proc = 1
                if bypass_proc == 0:
                    #åƒè¼¸å…¥çš„æ¨æ–‡æ•¸
                    try:
                        simple_push_rate = int(simple_board_name_input[3])
                    except:
                        #print("........input push rate fail1")
                        simple_push_rate = 50
                    print("........push_rate_1" + str(simple_push_rate))
                    simple_filter_type = 2
                    all_template_message = ptt_simple_board(simple_board_name, simple_push_rate, filter_simple, simple_filter_type)
                    #print(all_template_message)
                    print(len(all_template_message))
                    if not all_template_message:
                        if search_match <=0:
                            all_template_message = \
                            "æŸ¥ç„¡çµæœï¼Œè«‹èª¿æ•´æœå°‹é—œéµå­—ï¼ŒLzPttsæŒ‡ä»¤èªªæ˜: \n\n" + \
                            "LzPtts (ç©ºæ ¼) PTTç‰ˆå (ç©ºæ ¼) æœå°‹é—œéµå­— (ç©ºæ ¼) æ¨æ–‡æ•¸æ¨™æº–\n\n" + \
                            "ä¾‹: LzPtts car å¿ƒå¾—\n" + \
                            "ä¾‹: LzPtts nba box 70\n"
                        elif push_rate_match <= 0:
                            all_template_message = \
                            "è«‹é™ä½æ¨æ–‡æ•¸æ¨™æº–ï¼ŒLzPttsæŒ‡ä»¤èªªæ˜: \n\n" + \
                            "LzPtts (ç©ºæ ¼) PTTç‰ˆå (ç©ºæ ¼) æœå°‹é—œéµå­— (ç©ºæ ¼) æ¨æ–‡æ•¸æ¨™æº–\n\n" + \
                            "ä¾‹: LzPtts car å¿ƒå¾—\n" + \
                            "ä¾‹: LzPtts nba box 70\n"
                    if len(all_template_message) >= 2000:
                        all_template_message = \
                        "æ–‡ç« éå¤šï¼Œè«‹èª¿æ•´è¨­å®šï¼ŒLzPttsæŒ‡ä»¤èªªæ˜: ã€‚\n\n" + \
                        "LzPtts (ç©ºæ ¼) PTTç‰ˆå (ç©ºæ ¼) æœå°‹é—œéµå­— (ç©ºæ ¼) æ¨æ–‡æ•¸æ¨™æº–\n\n" + \
                        "ä¾‹: LzPtts car å¿ƒå¾—\n" + \
                        "ä¾‹: LzPtts nba box 70\n"
                line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text=all_template_message)
                )

            if event.message.text.lower() == 'beau':
                all_template_message = ''
                article_list_sorted = PttBeautyCarousel()
                print(article_list_sorted)
                all_template_message = TemplateSendMessage(
                    #PCç‰ˆä¸æ”¯æ´CarouselTemplateï¼Œåªæœƒé¡¯ç¤ºé€™æ®µè¨Šæ¯ï¼Œæ‰‹æ©Ÿæ¿å‰›å¥½ä¸æœƒé¡¯ç¤ºï¼Œæ‹¿ä¾†ç•¶PCç‰ˆçš„è³‡è¨Šæ¬„ä½
                    alt_text = "PTTè¡¨ç‰¹ç‰ˆè¿‘æ—¥æ¨æ–‡æ•¸å‰5å\n\n" + "(" + str(article_list_sorted[0][0]) + "æ¨) " \
                     + article_list_sorted[0][2] + "\n" + article_list_sorted[0][1] \
                     + "\n\n" + "(" + str(article_list_sorted[1][0]) + "æ¨) " \
                     + article_list_sorted[1][2] + "\n" + article_list_sorted[1][1] \
                     + "\n\n" + "(" + str(article_list_sorted[2][0]) + "æ¨) " \
                     + article_list_sorted[2][2] + "\n" + article_list_sorted[2][1] \
                     + "\n\n" + "(" + str(article_list_sorted[3][0]) + "æ¨) " \
                     + article_list_sorted[3][2] + "\n" + article_list_sorted[3][1] \
                     + "\n\n" + "(" + str(article_list_sorted[4][0]) + "æ¨) " \
                     + article_list_sorted[4][2] + "\n" + article_list_sorted[4][1] \
                     ,
                    template = CarouselTemplate(
                        columns = [
                            CarouselColumn(
                                thumbnail_image_url = article_list_sorted[0][3],
                                #åæ­£CarouselTemplateçš„titleæ¬„ä½éå¿…è¦ï¼Œæ”¾äº†ä¹Ÿæ²’æ¯”è¼ƒå¥½çœ‹ï¼Œå°±çœæ‰
                                #title = "( " + str(article_list_sorted[0][0]) + "æ¨ )",
                                text = "( " + str(article_list_sorted[0][0]) + "æ¨ ) " + article_list_sorted[0][2],
                                actions = [
                                    URITemplateAction(
                                        label = "PTTåŸæ–‡é€£çµ",
                                        uri = article_list_sorted[0][1]
                                    )
                                ]
                            ),
                            CarouselColumn(
                                thumbnail_image_url = article_list_sorted[1][3],
                                #title = "( " + str(article_list_sorted[1][0]) + "æ¨ ) ",
                                text = "( " + str(article_list_sorted[1][0]) + "æ¨ ) " + article_list_sorted[1][2],
                                actions = [
                                    URITemplateAction(
                                        label = "PTTåŸæ–‡é€£çµ",
                                        uri = article_list_sorted[1][1]
                                    )
                                ]
                            ),
                            CarouselColumn(
                                thumbnail_image_url = article_list_sorted[2][3],
                                #title = "( " + str(article_list_sorted[2][0]) + "æ¨ )",
                                text = "( " + str(article_list_sorted[2][0]) + "æ¨ ) " + article_list_sorted[2][2],
                                actions = [
                                    URITemplateAction(
                                        label = "PTTåŸæ–‡é€£çµ",
                                        uri = article_list_sorted[2][1]
                                    )
                                ]
                            ),
                            CarouselColumn(
                                thumbnail_image_url = article_list_sorted[3][3],
                                #title = "( " + str(article_list_sorted[3][0]) + "æ¨ )",
                                text = "( " + str(article_list_sorted[3][0]) + "æ¨ ) " + article_list_sorted[3][2],
                                actions = [
                                    URITemplateAction(
                                        label = "PTTåŸæ–‡é€£çµ",
                                        uri = article_list_sorted[3][1]
                                    )
                                ]
                            ),
                            CarouselColumn(
                                thumbnail_image_url = article_list_sorted[4][3],
                                #title = "( " + str(article_list_sorted[4][0]) + " æ¨)",
                                text = "( " + str(article_list_sorted[4][0]) + " æ¨) " + article_list_sorted[4][2],
                                actions = [
                                    URITemplateAction(
                                        label = "PTTåŸæ–‡é€£çµ",
                                        uri = article_list_sorted[4][1]
                                    )
                                ]
                            )
                        ]
                    )
                )
                line_bot_api.reply_message(
                event.reply_token,
                all_template_message
                )
                #ç”¨å®ŒæŠŠlistå…§å®¹åˆªæ‰ï¼Œé”åˆ°é‡ç½®çš„æ•ˆæœï¼Œä¸ç„¶èˆŠçš„ç´€éŒ„é‚„åœ¨ï¼Œçµæœç´¯ç©æ¨æ–‡æ•¸æœ€é«˜çš„é‚£ç¯‡
            # article_list = []
            # article_list_sorted = []
            del all_template_message
            del article_list[:]
            del article_list_sorted[:]
            simple_board_name = ""
            simple_push_rate is None
            del filter_simple[:]

    return 'OK'
article_list = []
push_rate_match = 0
search_match = 0
push_rate_peak = 0

def crawPageBeauty(url, push_rate, soup):
    #r-entæ˜¯æ¯é è£¡é¢å„ç¯‡æ–‡çš„class
    for r_ent in soup.find_all(class_="r-ent"):
        try:
            #æŠ“å„ç¯‡æ–‡ç« uriçš„å¾ŒåŠæ®µ
            link = r_ent.find('a')['href']
            if 'M.1430099938.A.3B7' in link:
                continue
            comment_rate = ""
            if (link):
                #æ–‡ç« uriå­˜åœ¨çš„è©±ï¼Œè¡¨ç¤ºæ²’è¢«åˆªæ–‡ï¼Œå¯ä»¥ç¹¼çºŒæŠ“å€¼(æ¨™é¡Œã€æ¨æ–‡æ•¸)ï¼Œå› ç‚ºlinkçš„ç¶²å€åªæœ‰å¾ŒåŠæ®µï¼Œè‡ªå·±æ¥èµ·ä¾†
                title = r_ent.find(class_="title").text.strip()
                rate = r_ent.find(class_="nrec").text
                URL = 'https://www.ptt.cc' + link
                #print("........" + URL)
                if (rate):
                    comment_rate = rate
                    if rate.find(u'çˆ†') > -1:
                        comment_rate = 100
                    if rate.find('X') > -1:
                        comment_rate = -1 * int(rate[1])
                else:
                    comment_rate = 0
                #åªçœ‹æ¨æ–‡æ•¸ >= push_rateè¨­å®šçš„
                if int(comment_rate) >= push_rate:
                    #print("        HighPost: " + URL)
                    #æŠ“URLç¶²é å…§å®¹çµ¦res_post
                    res_post = requests.get(URL, verify=False)
                    #æŠŠç¶²é å…§å®¹parseréå¾Œä¸Ÿçµ¦soup_post
                    soup_post = BeautifulSoup(res_post.text, "lxml")
                    #æ¯”è¼ƒåƒæš«æ™‚è§£ï¼Œå› ç‚ºæˆ‘æŠ“å…¨éƒ¨<a >ä½†å‰5å€‹æœƒæ˜¯PTTçš„é€£çµï¼Œå¾Œé¢æ‰é–‹å§‹æ˜¯poæ–‡å…§çš„ï¼Œå°±è¨­å®šå€‹èµ·å§‹å€¼é™loading
                    img_uri_num = 5
                    img_links_list = []
                    #æ²’æ‰“ç®—æŠ“å¾ˆå¤šé€£çµä¾†åˆ†æï¼Œåªè¦æœ‰ä¸€å¼µåœ–å°±å¯ä»¥äº†ï¼Œè®“ä»–æŠ“ç¬¬5åˆ°10å€‹é€£çµ
                    for img_uri_num in range(img_uri_num, 10, +1):
                        #print(img_uri_num)
                        img_links = soup_post.select("a")[img_uri_num]["href"]
                        #print(img_links)
                        #å¦‚æœè©²é€£çµçµå°¾æ˜¯.jpgï¼Œé‚£å°±å¯ä»¥ç”¨
                        if img_links.lower().endswith(".jpg"):
                            #å¦‚æœæ˜¯httpså°±OKï¼Œä¸æ˜¯çš„è©±è¦æŠŠhttpæ›æˆhttpsï¼ŒLINEä¸æ”¯æ´httpçš„åœ–
                            if not img_links.startswith("https://"):
                                img_links = re.sub("http", "https", img_links)
                                #print(img_links)
                            #é›–ç„¶åªè¦ä¸€å¼µï¼Œä½†æŠ“éƒ½æŠ“äº†ï¼Œå­˜å€‹5å¼µå…ˆï¼Œå¯èƒ½å¾Œé¢æœ‰ç”¨
                            img_links_list.append(img_links)
                        #é.jpgçµå°¾çš„ï¼Œå¦‚æœæ˜¯imguråœ–åºŠçš„ï¼Œå¹«ä»–åŠ å€‹
                        elif "imgur" in img_links:
                            img_links = img_links + ".jpg"
                            print(img_links)
                            if not img_links.startswith("https://"):
                                img_links = re.sub("http", "https", img_links)
                                #print(img_links)
                            #é›–ç„¶åªè¦ä¸€å¼µï¼Œä½†æŠ“éƒ½æŠ“äº†ï¼Œæœ‰å¹¾å¼µå­˜å¹¾å¼µï¼Œå¯èƒ½å¾Œé¢æœ‰ç”¨
                            img_links_list.append(img_links)
                    #ä¸€ç¯‡æ–‡çš„è³‡æ–™æŠ“å®Œäº†ï¼Œå­˜é€²list
                    article_list.append((int(comment_rate), URL, title, img_links_list[0]))                
        except:
            # print u'crawPage function error:',r_ent.find(class_="title").text.strip()
            # print('æœ¬æ–‡å·²è¢«åˆªé™¤')
            print('delete')

def simple_craw_page(url, push_rate, soup, filter_simple, simple_filter_type):
    #r-entæ˜¯æ¯é è£¡é¢å„ç¯‡æ–‡çš„class
    #print(filter_softjob)
    global push_rate_match
    global search_match
    global push_rate_peak
    for r_ent in soup.find_all(class_="r-ent"):
        try:
            #æŠ“å„ç¯‡æ–‡ç« uriçš„å¾ŒåŠæ®µ
            link = r_ent.find('a')['href']
            # if 'M.1430099938.A.3B7' in link:
            #     continue
            comment_rate = ""
            if (link):
                #æ–‡ç« uriå­˜åœ¨çš„è©±ï¼Œè¡¨ç¤ºæ²’è¢«åˆªæ–‡ï¼Œå¯ä»¥ç¹¼çºŒæŠ“å€¼(æ¨™é¡Œã€æ¨æ–‡æ•¸)ï¼Œå› ç‚ºlinkçš„ç¶²å€åªæœ‰å¾ŒåŠæ®µï¼Œè‡ªå·±æ¥èµ·ä¾†
                title = r_ent.find(class_="title").text.strip()
                rate = r_ent.find(class_="nrec").text
                URL = 'https://www.ptt.cc' + link
                #print("........" + URL)
                if (rate):
                    comment_rate = rate
                    if rate.find(u'çˆ†') > -1:
                        comment_rate = 100
                    if rate.find('X') > -1:
                        comment_rate = -1 * int(rate[1])
                else:
                    comment_rate = 0
                #åªçœ‹æ¨æ–‡æ•¸ >= push_rateè¨­å®šçš„ï¼ŒåŒæ™‚ä¾æ¨™é¡Œåˆ†é¡é»‘åå–®éæ¿¾
                if simple_filter_type == 1:                    
                    if int(comment_rate) >= push_rate and not (title.lower().startswith(tuple(filter_simple))):
                        article_list.append((int(comment_rate), URL, title))
                        #print(article_list)
                    elif not title.lower().startswith(tuple(filter_simple)):
                        push_rate_peak = int(comment_rate)
                        print("............push peak: " + comment_rate)
                elif simple_filter_type == 2:
                    print(str(comment_rate) + "   keyword   " + filter_simple.lower() + "  >?  " + title.lower() + "\n\n")
                    # print(filter_simple.encode("UTF-8"))
                    # print("\n")
                    # print(title.encode("UTF-8"))
                    if int(comment_rate) >= push_rate and (filter_simple.lower() in title.lower()):
                        article_list.append((int(comment_rate), URL, title))
                        push_rate_match += 1
                        print("......push status is : " + str(push_rate_match))
                        # print(article_list)                    
        except:
            # print u'crawPage function error:',r_ent.find(class_="title").text.strip()
            # print('æœ¬æ–‡å·²è¢«åˆªé™¤')
            print('delete')
    #print(article_list)

# def crawPageNBA(url, push_rate, soup):
#     #r-entæ˜¯æ¯é è£¡é¢å„ç¯‡æ–‡çš„class
#     for r_ent in soup.find_all(class_="r-ent"):
#         try:
#             #æŠ“å„ç¯‡æ–‡ç« uriçš„å¾ŒåŠæ®µ
#             link = r_ent.find('a')['href']
#             # if 'M.1430099938.A.3B7' in link:
#             #     continue
#             comment_rate = ""
#             if (link):
#                 #æ–‡ç« uriå­˜åœ¨çš„è©±ï¼Œè¡¨ç¤ºæ²’è¢«åˆªæ–‡ï¼Œå¯ä»¥ç¹¼çºŒæŠ“å€¼(æ¨™é¡Œã€æ¨æ–‡æ•¸)ï¼Œå› ç‚ºlinkçš„ç¶²å€åªæœ‰å¾ŒåŠæ®µï¼Œè‡ªå·±æ¥èµ·ä¾†
#                 title = r_ent.find(class_="title").text.strip()
#                 rate = r_ent.find(class_="nrec").text
#                 URL = 'https://www.ptt.cc' + link
#                 #print("........" + URL)
#                 if (rate):
#                     comment_rate = rate
#                     if rate.find(u'çˆ†') > -1:
#                         comment_rate = 100
#                     if rate.find('X') > -1:
#                         comment_rate = -1 * int(rate[1])
#                 else:
#                     comment_rate = 0
#                 #åªçœ‹æ¨æ–‡æ•¸ >= push_rateè¨­å®šçš„
#                 #print("................" + str(comment_rate) + title)
#                 if int(comment_rate) >= push_rate and not re.search("[live]", title, re.IGNORECASE) and not re.search("[å…¬å‘Š]", title):
#                 #if int(comment_rate) >= push_rate:
#                     #print(comment_rate + title)
#                     article_list.append((int(comment_rate), URL, title))                
#         except:
#             # print u'crawPage function error:',r_ent.find(class_="title").text.strip()
#             # print('æœ¬æ–‡å·²è¢«åˆªé™¤')
#             print('delete')

# def PttBeauty():
#     TargetURI = "https://www.ptt.cc/bbs/Beauty/index.html"
#     res = requests.get(TargetURI, verify=False)
#     #print(res.text)
#     #ResContent = res.text
#     soup = BeautifulSoup(res.text, "lxml")
#     #print("    soup>>>" + soup.prettify())
#     #class=btn wide
#     LatestPageURI = soup.select('.btn.wide')[1]['href']
#     #print("    URI>>> " + LatestPageURI)
#     LatestPageNum = re.match('/bbs/Beauty/index(.*).html',LatestPageURI)
#     #print("    PageNum>>> " + LatestPageNum.group(1))
#     LPN = int(LatestPageNum.group(1)) + 1
#     push_rate = 30  # æ¨æ–‡
#     page_uri_list = []
#     for page in range(LPN, LPN-3, -1):
#         page_uri = "https://www.ptt.cc/bbs/Beauty/index" + str(page) + ".html"
#         page_uri_list.append(page_uri)
#     #print("    PageURI>>> " + page_uri)
#     #print(page_uri_list)
#     while page_uri_list:
#         index = page_uri_list.pop(0)
#         #print("    try to parse: " + index)
#         res = requests.get(index, verify=False)
#         soup = BeautifulSoup(res.text, 'lxml')
#         # å¦‚ç¶²é å¿™ç·šä¸­,å‰‡å…ˆå°‡ç¶²é åŠ å…¥ index_list ä¸¦ä¼‘æ¯1ç§’å¾Œå†é€£æ¥
#         if (soup.title.text.find('Service Temporarily') > -1):
#             page_uri_list.append(index)
#             # print u'error_URL:',index
#             # time.sleep(1)
#         else:
#             crawPageBeauty(index, push_rate, soup)
#             # print u'OK_URL:', index
#             # time.sleep(0.05)
#     article_list_sorted = []
#     article_list_sorted = sorted(article_list, key = lambda x:x[0], reverse = True)
#     #print(article_list_sorted)
#     all_template_message = ''
#     for article in article_list_sorted:
#         data = "(" + str(article[0]) + "æ¨) " + article[2] + "\n" + article[1] + "\n" + article[3] + "\n\n"
#         all_template_message += data
#     return all_template_message

def PttBeautyCarousel():
    TargetURI = "https://www.ptt.cc/bbs/Beauty/index.html"
    res = requests.get(TargetURI, verify=False)
    #print(res.text)
    #ResContent = res.text
    soup = BeautifulSoup(res.text, "lxml")
    #print("    soup>>>" + soup.prettify())
    #çˆ¬æœ€æ–°-1é é¢é€£çµ(å› ç‚ºç›´æ¥getçš„è©±ï¼Œç¬¬1é æ˜¯index.html)
    LatestPageURI = soup.select('.btn.wide')[1]['href']
    #print("    URI>>> " + LatestPageURI)
    #å¾é€£çµæŠ“å‡ºæœ€æ–°-1é æ•¸
    LatestPageNum = re.match('/bbs/Beauty/index(.*).html',LatestPageURI)
    #print("    PageNum>>> " + LatestPageNum.group(1))
    #æœ€æ–°é é›–ç„¶æ˜¯index.htmlï¼Œä½†å‰›å‰›çš„æ•¸å­—+1ä¹Ÿèƒ½é€£çš„åˆ°ï¼Œæ‰€ä»¥+1ä¾†ç”¨
    LPN = int(LatestPageNum.group(1)) + 1
    #è¨­å€‹é–¥å€¼ï¼Œæƒ³é™äº›loadingï¼Œé€™æ”¯parserå¥½åƒä¸å¤ªå¿«
    push_rate = 20  # æ¨æ–‡
    page_uri_list = []
    #æŠ“å€‹3é å·®ä¸å¤šå§ï¼Œè¡¨ç‰¹ç‰ˆæ–‡ç« æ›´æ–°ä¸ç®—å¿«ï¼ŒæŠŠé€™ä¸‰é çš„uriæ¥å¥½å­˜åˆ°page_uri_list
    for page in range(LPN, LPN-3, -1):
        page_uri = "https://www.ptt.cc/bbs/Beauty/index" + str(page) + ".html"
        page_uri_list.append(page_uri)
    #print("    PageURI>>> " + page_uri)
    #print(page_uri_list)
    while page_uri_list:
        index = page_uri_list.pop(0)
        #print("    try to parse: " + index)
        #çˆ¬é é¢å…§å®¹å‡ºä¾†
        res = requests.get(index, verify=False)
        soup = BeautifulSoup(res.text, 'lxml')
        #å¦‚ç¶²é å¿™ç·šä¸­,å‰‡å…ˆå°‡ç¶²é åŠ å…¥page_uri_listç­‰1ç§’å¾Œé‡è©¦
        if (soup.title.text.find('Service Temporarily') > -1):
            page_uri_list.append(index)
            # print u'error_URL:',index
            # time.sleep(1)
        else:
            crawPageBeauty(index, push_rate, soup)
            # print u'OK_URL:', index
            # time.sleep(0.05)
    article_list_sorted = []
    article_list_sorted = sorted(article_list, key = lambda x:x[0], reverse = True)
    #print(article_list_sorted)    
    # for article in article_list_sorted:
    #     data = "(" + str(article_list_sorted[0]) + "æ¨) " + article_list_sorted[2] + "\n" + article_list_sorted[1] + "\n" + article_list_sorted[3] + "\n\n"
    #     all_template_message += data
    return article_list_sorted

def ptt_simple_board(simple_board_name, simple_push_rate, filter_simple, simple_filter_type):
    global search_match
    global push_rate_match
    global push_rate_peak
    search_match = 0
    push_rate_match = 0
    push_rate_peak = 0
    #åƒå‚³é€²ä¾†çš„æ¿å(simple_board_name)
    TargetURI = "https://www.ptt.cc/bbs/" + simple_board_name + "/index.html"
    rs = requests.session()
    if simple_board_name in ["gossiping", "sex"]:
        #print("........start to verify 18+")
        adult_payload = {
        "from" : "/bbs/" + simple_board_name + "/index.html",
        "yes" : "yes"
        }
        res = rs.post("https://www.ptt.cc/ask/over18", verify=False, data = adult_payload)
        #print(res.text)

    res = rs.get(TargetURI, verify=False)
    #print(res.text)
    #ResContent = res.text
    soup = BeautifulSoup(res.text, "lxml")
    #print("    soup>>>" + soup.prettify())
    #class=btn wide
    #æŠ“æœ€æ–°-1é é€£çµ
    try:
        LatestPageURI = soup.select('.btn.wide')[1]['href']
    except:
        all_template_message = "ç™¼ç”ŸéŒ¯èª¤ï¼Œå¯è‡³PTTç¢ºèªç‰ˆåã€‚\n https://www.ptt.cc/hotboard.html"
        return all_template_message
    #print("    URI>>> " + LatestPageURI)
    #å¾é€£æ¥æ‹†å‡ºæœ€æ–°-1é æ•¸
    noindex_page_uri = re.split("index", LatestPageURI)
    #print(noindex_page_uri)
    #print(noindex_page_uri[1][0:-5])
    LatestPageNum = noindex_page_uri[1][0:-5]
    #print( LatestPageNum )
    #print(LatestPageNum.group(1))
    LPN = int(LatestPageNum) + 1
    #åƒå‚³é€²ä¾†çš„æ¨æ–‡é–¥å€¼
    push_rate = simple_push_rate
    print("....push_erate = simple..." + str(push_rate))
    page_uri_list = []
    #æŠ“3é ï¼ŒæŠŠuriæ¥èµ·ä¾†å­˜åœ¨page_uri_list
    for page in range(LPN, LPN-3, -1):
        page_uri = "https://www.ptt.cc/bbs/" + simple_board_name + "/index" + str(page) + ".html"
        page_uri_list.append(page_uri)
    #print("    PageURI>>> " + page_uri)
    #print(page_uri_list)
    while page_uri_list:
        index = page_uri_list.pop(0)
        #print("    try to parse: " + index)

        res = rs.get(index, verify=False)
        soup = BeautifulSoup(res.text, 'lxml')
        #å¦‚ç¶²é å¿™ç·šä¸­,å‰‡å…ˆå°‡ç¶²é åŠ å…¥page_uri_listç­‰1ç§’é‡è©¦
        if (soup.title.text.find('Service Temporarily') > -1):
            page_uri_list.append(index)
            # print u'error_URL:',index
            # time.sleep(1)
        else:
            simple_craw_page(index, push_rate, soup, filter_simple, simple_filter_type)
            # print u'OK_URL:', index
            # time.sleep(0.05)
    #print(article_list)
    article_list_sorted = []
    article_list_sorted = sorted(article_list, key = lambda x:x[0], reverse = True)
    #print(article_list_sorted)
    all_template_message = ''
    for article in article_list_sorted:
        data = "(" + str(article[0]) + "æ¨) " + article[2] + "\n" + article[1] + "\n\n"
        all_template_message += data
    return all_template_message

# def PttNBA():
#     TargetURI = "https://www.ptt.cc/bbs/NBA/index.html"
#     res = requests.get(TargetURI, verify=False)
#     #print(res.text)
#     #ResContent = res.text
#     soup = BeautifulSoup(res.text, "lxml")
#     #print("    soup>>>" + soup.prettify())
#     #class=btn wide
#     #æŠ“æœ€æ–°-1é çš„é€£çµ
#     LatestPageURI = soup.select('.btn.wide')[1]['href']
#     #print("    URI>>> " + LatestPageURI)
#     #å¾é€£æ¥æ‹†å‡ºæœ€æ–°-1é æ•¸
#     LatestPageNum = re.match('/bbs/NBA/index(.*).html',LatestPageURI)
#     #print("    PageNum>>> " + LatestPageNum.group(1))
#     LPN = int(LatestPageNum.group(1)) + 1
#     #è¨­å®šæ¨æ–‡æ•¸é–¥å€¼
#     push_rate = 50
#     page_uri_list = []
#     for page in range(LPN, LPN-3, -1):
#         page_uri = "https://www.ptt.cc/bbs/NBA/index" + str(page) + ".html"
#         page_uri_list.append(page_uri)
#     #print("    PageURI>>> " + page_uri)
#     #print(page_uri_list)
#     while page_uri_list:
#         index = page_uri_list.pop(0)
#         #print("    try to parse: " + index)
#         res = requests.get(index, verify=False)
#         soup = BeautifulSoup(res.text, 'lxml')
#         #å¦‚ç¶²é å¿™ç·šä¸­,å‰‡å…ˆå°‡ç¶²é åŠ å…¥page_uri_listç­‰1ç§’é‡è©¦
#         if (soup.title.text.find('Service Temporarily') > -1):
#             page_uri_list.append(index)
#             # print u'error_URL:',index
#             # time.sleep(1)
#         else:
#             crawPageNBA(index, push_rate, soup)
#             # print u'OK_URL:', index
#             # time.sleep(0.05)
#     article_list_sorted = []
#     article_list_sorted = sorted(article_list, key = lambda x:x[0], reverse = True)
#     #print(article_list_sorted)
#     all_template_message = ''
#     for article in article_list_sorted:
#         data = "(" + str(article[0]) + "æ¨) " + article[2] + "\n" + article[1] + "\n\n"
#         all_template_message += data
#     return all_template_message

# def PttNBAFilm():
#     TargetURI = "https://www.ptt.cc/bbs/NBA_Film/index.html"
#     res = requests.get(TargetURI, verify=False)
#     #print(res.text)
#     #ResContent = res.text
#     soup = BeautifulSoup(res.text, "lxml")
#     #print("    soup>>>" + soup.prettify())
#     #class=btn wide
#     #æŠ“æœ€æ–°-1é çš„é€£çµ
#     LatestPageURI = soup.select('.btn.wide')[1]['href']
#     #print("    URI>>> " + LatestPageURI)
#     #å¾é€£æ¥æ‹†å‡ºæœ€æ–°-1é æ•¸
#     LatestPageNum = re.match('/bbs/NBA_Film/index(.*).html',LatestPageURI)
#     #print("    PageNum>>> " + LatestPageNum.group(1))
#     LPN = int(LatestPageNum.group(1)) + 1
#     #è¨­å®šæ¨æ–‡æ•¸é–¥å€¼
#     push_rate = 20
#     page_uri_list = []
#     for page in range(LPN, LPN-3, -1):
#         page_uri = "https://www.ptt.cc/bbs/NBA_Film/index" + str(page) + ".html"
#         page_uri_list.append(page_uri)
#     #print("    PageURI>>> " + page_uri)
#     #print(page_uri_list)
#     while page_uri_list:
#         index = page_uri_list.pop(0)
#         #print("    try to parse: " + index)
#         res = requests.get(index, verify=False)
#         soup = BeautifulSoup(res.text, 'lxml')
#         #å¦‚ç¶²é å¿™ç·šä¸­,å‰‡å…ˆå°‡ç¶²é åŠ å…¥page_uri_listç­‰1ç§’é‡è©¦
#         if (soup.title.text.find('Service Temporarily') > -1):
#             page_uri_list.append(index)
#             # print u'error_URL:',index
#             # time.sleep(1)
#         else:
#             crawPageNBA(index, push_rate, soup)
#             # print u'OK_URL:', index
#             # time.sleep(0.05)
#     article_list_sorted = []
#     article_list_sorted = sorted(article_list, key = lambda x:x[0], reverse = True)
#     #print(article_list_sorted)
#     all_template_message = ''
#     for article in article_list_sorted:
#         data = "(" + str(article[0]) + "æ¨) " + article[2] + "\n" + article[1] + "\n\n"
#         all_template_message += data
#     return all_template_message


if __name__ == "__main__":
    arg_parser = ArgumentParser(
        usage='Usage: python ' + __file__ + ' [--port <port>] [--help]'
    )
    arg_parser.add_argument('-p', '--port', default=8000, help='port')
    arg_parser.add_argument('-d', '--debug', default=False, help='debug')
    options = arg_parser.parse_args()

    app.run(debug=options.debug, port=options.port)